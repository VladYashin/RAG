{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query Extension\n",
    "\n",
    "Sometimes people don't know exactly what they want to ask or can't precisely formulate their questions. The **Query Extension** step aims to solve this problem by generating multiple similar queries that can be used to enhance the original query. This technique is particularly useful in improving the retrieval component.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import os\n",
    "\n",
    "# langchain\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# init OpenAI (or any other open source model)\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "AZURE_OPENAI_ENDPOINT = os.environ.get('AZURE_OPENAI_ENDPOINT')\n",
    "AZURE_OPENAI_VERSION = os.environ.get('AZURE_OPENAI_VERSION')\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ.get('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "\n",
    "oai = AzureChatOpenAI(\n",
    "    openai_api_version=AZURE_OPENAI_VERSION,\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    temperature=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL NO. OF CHUNKS:  66\n"
     ]
    }
   ],
   "source": [
    "# basic retriever\n",
    "\n",
    "data_path = \"../data\"\n",
    "files = [\"fishingguide1.pdf\", \"fishingguide2.pdf\"]\n",
    "\n",
    "data = [PyPDFLoader(os.path.join(data_path, file)).load() for file in files]\n",
    "docs_list = [item for sublist in data for item in sublist]\n",
    "text_splitter = NLTKTextSplitter()\n",
    "doc_chunks = text_splitter.split_documents(docs_list)\n",
    "\n",
    "print(\"TOTAL NO. OF CHUNKS: \", len(doc_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_model = SentenceTransformerEmbeddings(model_name=\"thenlper/gte-large\")\n",
    "db = Chroma.from_documents(documents=doc_chunks, embedding=emb_model,\n",
    "                           collection_metadata={\"hnsw:space\": \"cosine\"})\n",
    "retriever = db.as_retriever(search_type=\"mmr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to catch fish USA',\n",
       " 'Fishing techniques in USA',\n",
       " 'Best ways to catch fish in USA',\n",
       " 'USA fishing guide',\n",
       " 'How to fish in America']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OPTION 1: generate similar queries\n",
    "\n",
    "def generate_similar_queries(initial_query):\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=f\"\"\"\n",
    "\n",
    "            You are a helpful search assistant. Your task is to generate four similar search queries based on a single input query. \n",
    "            Always use provided output for your response. Be concise and constructive. Do not deviate from the context.\n",
    "            Initial single input query: {initial_query}\n",
    "            Output sturcture: [\"{initial_query}\", search query 1, search query 2, search query 3, search query 4]\n",
    "\n",
    "        \"\"\",\n",
    "\n",
    "    )\n",
    "    response = oai.invoke([message])\n",
    "    queries = ast.literal_eval(response.content)\n",
    "\n",
    "    return queries\n",
    "\n",
    "\n",
    "user_query = \"How to catch fish USA\"\n",
    "similar_queries = generate_similar_queries(initial_query=user_query)\n",
    "similar_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'How to catch fish USA': 0.87898,\n",
       " 'How to fish in America': 0.87423,\n",
       " 'USA fishing guide': 0.87053,\n",
       " 'Fishing techniques in USA': 0.86862,\n",
       " 'Best ways to catch fish in USA': 0.86521}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# calculate cosine similarity for each of the queries\n",
    "\n",
    "def calculate_avg_similarity(queries):\n",
    "\n",
    "    averages = {}\n",
    "\n",
    "    for query in queries:\n",
    "        results = db.similarity_search_with_relevance_scores(query=query)\n",
    "        scores = [result[1] for result in results]\n",
    "        if scores:\n",
    "            averages[query] = round((sum(scores) / len(scores)), 5)\n",
    "        else:\n",
    "            averages[query] = 0\n",
    "\n",
    "    srted_avgs = dict(\n",
    "        sorted(averages.items(), key=lambda item: item[1], reverse=True))\n",
    "    return srted_avgs\n",
    "\n",
    "\n",
    "scores = calculate_avg_similarity(similar_queries)\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTION 2: generate similar queries & provide retrieved contenxt for quality enhancement\n",
    "\n",
    "def generate_similar_queries_with_docs(query, documets):\n",
    "\n",
    "    message = HumanMessage(\n",
    "        content=f\"\"\" \n",
    "            You are a helpful search assistant. Your task is to generate four similar search queries in relation to the provided documents based on a single input query. \n",
    "            Always use provided output for your response. Be concise and constructive. Do not deviate from the context of the provided documents.\n",
    "            \n",
    "\n",
    "            Initial single input query: {query}\n",
    "            Documents: {documets}\n",
    "            Output sturcture: [\"{query}\", search query 1, search query 2, search query 3, search query 4]\n",
    "\n",
    "        \"\"\",\n",
    "\n",
    "    )\n",
    "    response = oai.invoke([message])\n",
    "    queries = ast.literal_eval(response.content)\n",
    "\n",
    "    return queries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['How to catch fish USA',\n",
       " 'Fishing safety tips in the USA',\n",
       " 'Types of baits for fishing in the USA',\n",
       " 'How to handle and clean fish in the USA',\n",
       " 'Fishing regulations in the USA']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"How to catch fish USA\"\n",
    "initial_results = retriever.invoke(input=user_query)\n",
    "similar_queries_w_docs = generate_similar_queries_with_docs(query=user_query, documets=initial_results)\n",
    "similar_queries_w_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'How to handle and clean fish in the USA': 0.88943,\n",
       " 'Fishing safety tips in the USA': 0.88455,\n",
       " 'Fishing regulations in the USA': 0.88429,\n",
       " 'Types of baits for fishing in the USA': 0.88086,\n",
       " 'How to catch fish USA': 0.87898}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_w_docs = calculate_avg_similarity(similar_queries_w_docs)\n",
    "scores_w_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outcomes\n",
    "\n",
    "By adding more context to the process of generating similar queries, we can enhance the similarity of retrieved documents by simply adjusting the formulations of user queries.\n",
    "\n",
    "**Comparison of Outcomes without and with Documents:**\n",
    "\n",
    "| Without Documents                      | With Documents                                   |\n",
    "|----------------------------------------|--------------------------------------------------|\n",
    "| 'How to catch fish USA': **0.87898**       | 'How to handle and clean fish in the USA': **0.88943** |\n",
    "| 'How to fish in America': **0.87423**      | 'Fishing safety tips in the USA': **0.88455**        |\n",
    "| 'USA fishing guide': 0.87053           | 'Fishing regulations in the USA': 0.88429         |\n",
    "| 'Fishing techniques in USA': 0.86862   | 'Types of baits for fishing in the USA': 0.88086  |\n",
    "| 'Best ways to catch fish in USA': 0.86521 | 'How to catch fish USA': 0.87898              |\n",
    "\n",
    "**IDEAS:**\n",
    "- Improve the system prompt for generating similar queries\n",
    "- Test different similarity metrics\n",
    "- Add a keyword-based scoring/re-ranking mechanism\n",
    "- Adjust the number of k for retrieval (to see if results improve or worsen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
