{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Azure AI Search Document Indexing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "import os\n",
    "import logging\n",
    "from typing import Any\n",
    "import shutil\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain.text_splitter import NLTKTextSplitter\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "AZURE_AI_SEARCH_ENDPOINT = os.environ[\"AZURE_AI_SEARCH_ENDPOINT\"]\n",
    "AZURE_AI_SEARCH_API_KEY = os.environ[\"AZURE_AI_SEARCH_API_KEY\"]\n",
    "AZURE_STORAGE_ACC_CONNECTION_STRING = os.environ[\"AZURE_STORAGE_ACC_CONNECTION_STRING\"]\n",
    "BLOB_CONTAINER_NAME = os.environ[\"BLOB_CONTAINER_NAME\"]\n",
    "\n",
    "\n",
    "AZURE_OPENAI_API_KEY = os.environ[\"AZURE_OPENAI_API_KEY\"]\n",
    "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "AZURE_OPENAI_VERSION = os.environ[\"AZURE_OPENAI_VERSION\"]\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME = os.environ[\"AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME\"]\n",
    "\n",
    "DOC_INTELLIGENCE_ENDPOINT = os.environ[\"DOC_INTELLIGENCE_ENDPOINT\"]\n",
    "DOC_INTELLIGENCE_KEY = os.environ[\"DOC_INTELLIGENCE_KEY\"]\n",
    "\n",
    "SEARCH_TARGET_INDEX_NAME = os.getenv(\"AZURE_AI_FISHING_INDEX\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure logging\n",
    "logging.basicConfig(level=logging.WARNING, format='%(asctime)s :: %(levelname)s :: %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize clients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Blob Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to Blob Storage container | SUCCESS: data\n"
     ]
    }
   ],
   "source": [
    "blob_service_client = BlobServiceClient.from_connection_string(AZURE_STORAGE_ACC_CONNECTION_STRING)\n",
    "container_client = blob_service_client.get_container_client(BLOB_CONTAINER_NAME)\n",
    "print(f\"Access to Blob Storage container | SUCCESS: {container_client.container_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to OpenAI generation model | SUCCESS: gpt4-32k-test-instance\n"
     ]
    }
   ],
   "source": [
    "oai_llm = AzureChatOpenAI(\n",
    "    openai_api_version=\"2024-02-01\",\n",
    "    azure_deployment=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "    temperature=0,\n",
    ")\n",
    "print(f\"Access to OpenAI generation model | SUCCESS: {oai_llm.deployment_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to OpenAI embedding model | SUCCESS: text-embedding-ada-002\n"
     ]
    }
   ],
   "source": [
    "oai_emb_model = AzureOpenAIEmbeddings(\n",
    "    azure_deployment=AZURE_OPENAI_EMBEDDING_DEPLOYMENT_NAME,\n",
    "    openai_api_version=\"2024-02-01\"\n",
    ")\n",
    "print(f\"Access to OpenAI embedding model | SUCCESS: {oai_emb_model.model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to AI Search client | SUCCESS: fishing-index-d\n"
     ]
    }
   ],
   "source": [
    "search_client = SearchClient(endpoint=AZURE_AI_SEARCH_ENDPOINT,\n",
    "                      index_name=SEARCH_TARGET_INDEX_NAME,\n",
    "                      credential=AzureKeyCredential(AZURE_AI_SEARCH_API_KEY))\n",
    "print(f\"Access to AI Search client | SUCCESS: {search_client._index_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to AI Search index client | SUCCESS: ['fishing-index-d', 'rag-vector-store-d']\n"
     ]
    }
   ],
   "source": [
    "search_index_client = SearchIndexClient(AZURE_AI_SEARCH_ENDPOINT, AzureKeyCredential(AZURE_AI_SEARCH_API_KEY))\n",
    "indexes = [index for index in search_index_client.list_index_names()]\n",
    "print(f\"Access to AI Search index client | SUCCESS: {indexes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to AI Search indexer client | SUCCESS: ['fishing-indexer-d', 'rag-vector-store-d-indexer']\n"
     ]
    }
   ],
   "source": [
    "search_indexer_client = SearchIndexerClient(AZURE_AI_SEARCH_ENDPOINT, AzureKeyCredential(AZURE_AI_SEARCH_API_KEY))\n",
    "indexers = search_indexer_client.get_indexer_names()\n",
    "print(f\"Access to AI Search indexer client | SUCCESS: {indexers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Intelligence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Access to Azure Document Intelligence | SUCCESS: <azure.ai.documentintelligence._patch.DocumentIntelligenceClient object at 0x00000229C8648290>\n"
     ]
    }
   ],
   "source": [
    "DI_KEY = AzureKeyCredential(DOC_INTELLIGENCE_KEY)\n",
    "di_client = DocumentIntelligenceClient(DOC_INTELLIGENCE_ENDPOINT, DI_KEY)\n",
    "print(f\"Access to Azure Document Intelligence | SUCCESS: {di_client}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download & process documents from blob storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (option 1) w/ temporary pdf generation locally\n",
    "\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "\n",
    "def load_documents_from_blob(container_client, doc_intelligence_key, doc_intelligence_endpoint):\n",
    "    docs = []\n",
    "\n",
    "    blob_list = container_client.list_blobs()\n",
    "    for blob in blob_list:\n",
    "        if blob.name.lower().endswith('.pdf'): # filter data types            \n",
    "            blob_client = container_client.get_blob_client(blob)\n",
    "\n",
    "            with open(\"temp.pdf\", \"wb\") as download_file:\n",
    "                download_file.write(blob_client.download_blob().readall())\n",
    "\n",
    "            # process the downloaded PDF with Azure AI Document Intelligence\n",
    "            doc = AzureAIDocumentIntelligenceLoader(\n",
    "                file_path=\"temp.pdf\",\n",
    "                api_key=doc_intelligence_key, \n",
    "                api_endpoint=doc_intelligence_endpoint, \n",
    "                api_model=\"prebuilt-layout\"\n",
    "            ).load()\n",
    "\n",
    "            # # add metafields | adjust metafields\n",
    "            doc[0].metadata[\"url\"] = str(blob_client.url)\n",
    "            doc[0].metadata[\"name\"] = str(blob.name)      \n",
    "            doc[0].metadata[\"container\"] = str(blob_client.container_name)\n",
    "\n",
    "            docs.append(doc)\n",
    "            os.remove(\"temp.pdf\")  # remove temp file\n",
    "\n",
    "    print(f\"Successfully loaded {len(docs)} documents!\")\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded 2 documents!\n"
     ]
    }
   ],
   "source": [
    "# load documents\n",
    "loaded_docs = load_documents_from_blob(container_client, DOC_INTELLIGENCE_KEY, DOC_INTELLIGENCE_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total no. of chunks:  13\n"
     ]
    }
   ],
   "source": [
    "# semantic chunking\n",
    "\n",
    "loaded_docs_list = [item for sublist in loaded_docs for item in sublist]\n",
    "\n",
    "def split_documents(docs_list):\n",
    "\n",
    "    text_splitter = NLTKTextSplitter(chunk_size=500)\n",
    "    doc_chunks = text_splitter.split_documents(docs_list)\n",
    "    print(\"Total no. of chunks: \", len(doc_chunks))\n",
    "    return doc_chunks\n",
    "\n",
    "doc_chunks = split_documents(loaded_docs_list) # keep as list of Documents for uploading via langchain instance\n",
    "doc_dict_chunks = [dict(doc) for doc in doc_chunks] # convert to list of dicts for Azure Document Intelligence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add content & metadata to Azure AI Search vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields in the index 'fishing-index-d':\n",
      "Field Name: id, Type: Edm.String, Searchable: False\n",
      "Field Name: content, Type: Edm.String, Searchable: True\n",
      "Field Name: metadata, Type: Edm.String, Searchable: True\n",
      "Field Name: content_vector, Type: Collection(Edm.Single), Searchable: True\n"
     ]
    }
   ],
   "source": [
    "def print_index_fields(search_index_client, index_name):\n",
    "\n",
    "    try:\n",
    "        index = search_index_client.get_index(index_name)\n",
    "        print(f\"Fields in the index '{index_name}':\")\n",
    "        for field in index.fields:\n",
    "            print(f\"Field Name: {field.name}, Type: {field.type}, Searchable: {field.searchable}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to retrieve index fields: {e}\")\n",
    "\n",
    "print_index_fields(search_index_client, SEARCH_TARGET_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup vector store\n",
    "\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    embedding_function=oai_emb_model.embed_query,\n",
    "    azure_search_endpoint=AZURE_AI_SEARCH_ENDPOINT,\n",
    "    azure_search_key=AZURE_AI_SEARCH_API_KEY,\n",
    "    index_name=SEARCH_TARGET_INDEX_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ZDBlZmE4MjYtZGM5Mi00Yzk1LTliNDItNGY1NmNjMTJlMDUx',\n",
       " 'YTU3MjEwYTAtNDQ1OS00YWNkLTgwNDctOGJiNDA5MWI2ZDFh',\n",
       " 'ZTIzNzY1ZDYtY2QyNC00Yjc4LWI1ODMtNjFlMDMxNDllMzIw',\n",
       " 'Yzg5MTIzYjYtZmQ5MC00NjA3LWJmNDAtYjI1NGIxYjlkNjAy',\n",
       " 'NzcxYThlYWQtNzJlYS00MjE3LWI1ODktYTRkNzc4NmJiNGY1',\n",
       " 'NjcxODk1NDktNzQ0My00OThhLWE2NmUtMzYzOWQzZjVmNzM5',\n",
       " 'MmE5ZTA1ZjYtZDU3OC00MDFlLTkwNjUtMDBkZTQ0NDFiNzkz',\n",
       " 'ZDYyMTUyY2YtMDRjZC00MTcwLWJiMmMtZTU4YzU0YWNiOTg5',\n",
       " 'M2E4YmU3NGItMTIyZi00ZjkyLWE1ZTEtYTA0MDkzMjI2MDhl',\n",
       " 'OTgzMTY5ZjctZWYyNS00OTMwLTk3NzAtYThmODkzZTI5MDc4',\n",
       " 'YmIxYzZiZWYtMWIyMS00MmI0LWIxYjctZDlmMjZmZDU0NGJl',\n",
       " 'MDUxMjcwYmMtZmJkNi00ZWNlLWFiNDUtZGVhODhlOWU0M2Ni',\n",
       " 'ODlhNTNlNzAtNjdiZi00YTk3LThmNzUtZThhYzYwYWIzN2Zk']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# upload documents to the index\n",
    "\n",
    "vector_store.add_documents(documents=doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "azure_retriever = vector_store.as_retriever(search_type=\"similarity\")\n",
    "\n",
    "system_prompt_template = \"\"\" \n",
    "    You are the most powerful and skillfull expert in querying documents to find answers to user's questions.\n",
    "    Your main task is to answer the USER QUERY based only on the provided CONTEXT.\n",
    "    # CONTEXT\n",
    "    {context}\n",
    "    # USER QUERY\n",
    "    {query}\n",
    "\"\"\"\n",
    "\n",
    "system_prompt = ChatPromptTemplate.from_template(system_prompt_template)\n",
    "\n",
    "chain = (\n",
    "    {\"context\": azure_retriever, \"query\": RunnablePassthrough()}\n",
    "    | system_prompt\n",
    "    | oai_llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"To reduce injury and handling time for the fish, use barbless or circle hooks and needlenose pliers or forceps. Also, land the fish as quickly as possible to minimize the fish's fighting time. When handling a fish, use wet hands and minimize the time out of water to 20 to 30 seconds.\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_query = \"How to reduce injury and handling time for the fish?\"\n",
    "\n",
    "chain.invoke(user_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
