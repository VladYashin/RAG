{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Evaluation w/ BERT Score\n",
    "\n",
    "The BERT score evaluates text by measuring the similarity between words in the context of their sentences. It differs from simple word matching because it considers the deeper, contextual meanings of each word.\n",
    "\n",
    "**STEP 1**: Create Embeddings\n",
    "First, generate contextual embeddings for both the **reference text** (the standard or target text) and the **candidate text** (the text you are evaluating).\n",
    "\n",
    "**STEP 2**: Calculate Similarities\n",
    "Use cosine similarity to determine how closely related the words are in the embeddings of the reference and candidate texts. \n",
    "\n",
    "**STEP 3**: Compute Precision and Recall\n",
    "- **Precision**: For each word in the candidate text, find the most similar word in the reference text and measure these matches --> High precision = low level of false positives --> 1 or 100% --> focus on correctness\n",
    "\n",
    "![precision](../images/prec-300x53.png)\n",
    "\n",
    "- **Recall**: For each word in the reference text, find the most similar word in the candidate text and measure these matches --> High recall = low level of false positives --> 1 or 100% --> focus on capturing all false positives\n",
    "\n",
    "![image-2.png](../images/recall-300x64.png)\n",
    "\n",
    "In practice, achieving both 100% precision and 100% recall is often impossible, leading to a trade-off:\n",
    "\n",
    "üî∏ A higher recall can be achieved at the expense of lower precision: capturing more positives but also increasing false positives.\n",
    "\n",
    "üî∏ A higher precision can be achieved at the cost of lower recall: fewer false positives but also missing more true positives.\n",
    "\n",
    "**STEP 4**: Compute F1\n",
    "\n",
    "Combine the results of Precision and Recall to calculate the F1 score, which provides a single measure of accuracy.\n",
    "\n",
    "- **High F1**: An F1 score near 1 is very good, indicating strong precision and recall.\n",
    "- **Low F1**: An F1 score near 0 is poor, indicating weak precision and recall.\n",
    "\n",
    "\n",
    "‚ùó **NOTE**: Remember, the embeddings assess **contextual** similarity, which reflects how words are used in specific contexts, rather than direct word-to-word similarity.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import modules\n",
    "\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ea40d294874762b091339136275b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfbbdcce097409ead971bffa63473d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 0.29 seconds, 3.46 sentences/sec\n",
      "Precision: 0.870\n",
      "Recall: 0.882\n",
      "F1 Score: 0.876\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "\n",
    "candidates = [\"In this article we will talk about cats\"]\n",
    "references = [\"This is a piece of text about kittens\"]\n",
    "\n",
    "P, R, F1 = score(candidates, references, lang='en', verbose=True)\n",
    "\n",
    "print(f\"Precision: {P.mean():.3f}\")\n",
    "print(f\"Recall: {R.mean():.3f}\")\n",
    "print(f\"F1 Score: {F1.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import RAG w/ Contextual Compression for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../1-rag-contextual-compression\")\n",
    "\n",
    "from rag_cc import RAGContextualCompression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(level=logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/rag-con-comp-data\"\n",
    "\n",
    "# step 1: initialize agent\n",
    "ragcc = RAGContextualCompression(data_path=data_path)\n",
    "\n",
    "# step 2: load & preprocess documents\n",
    "docs = ragcc.load_documents()\n",
    "doc_chunks = ragcc.preprocess_documents(docs)\n",
    "\n",
    "# step 3: initialize vector store\n",
    "db = ragcc.setup_vector_store(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yow yow, nice to see you here, curious mind! When an egg is boiled, the water present in the egg doesn't go anywhere but remains within the egg. The heat from boiling causes the proteins in the egg to denature and coagulate, trapping the water within the solidified egg white and yolk.\n"
     ]
    }
   ],
   "source": [
    "user_query = \"Where does the water present in the egg go after boiling the egg?\"\n",
    "\n",
    "# step 4: retrieve documents\n",
    "retrieved_docs = ragcc.retrieve_documents(db, user_query)\n",
    "\n",
    "# step 5: setup compression and redundancy filters to optimize document retrieval\n",
    "contextual_comp_retriever = ragcc.setup_compression_pipeline_retriever(db)\n",
    "\n",
    "# step 6: generate the final answer to the user query\n",
    "answer = ragcc.generate_answer(retriever=contextual_comp_retriever, user_query=user_query)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Reference Texts\n",
    "\n",
    "Reference texts are the texts that your model's output will be compared against. Ideally, high-quality human-generated texts that represent what you expect from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate references\n",
    "\n",
    "questions = [\n",
    "    \"What are monosaccharides?\",\n",
    "    \"What are reducing sugars?\",\n",
    "    \"What are two main functions of carbohydrates in plants?\",\n",
    "    \"Classify the following into monosaccharides and disaccharides: Ribose, 2-deoxyribose, maltose, galactose, fructose, lactose.\",\n",
    "    \"What do you understand by the term glycosidic linkage?\"\n",
    "]\n",
    "\n",
    "refs = [\n",
    "    \"Monosaccharides are carbohydrates that cannot be hydrolyzed further to give simpler units of polyhydroxy aldehyde or ketone.\",\n",
    "    \"Reducing sugars are those carbohydrates that can reduce Fehling‚Äôs solution and Tollens‚Äô reagent, including all monosaccharides whether aldose or ketose.\",\n",
    "    \"Carbohydrates act as a primary source of energy and serve as structural components within plant cells.\",\n",
    "    \"Monosaccharides: Ribose, 2-deoxyribose, galactose, fructose; Disaccharides: maltose, lactose.\",\n",
    "    \"A glycosidic linkage is a type of covalent bond that joins a carbohydrate molecule to another group, which can be another carbohydrate.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Generate Candidate Texts\n",
    "\n",
    "Candidate texts are the outputs generated by the imported RAG w/ Contextual Compression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create candidates\n",
    "\n",
    "cands = [ragcc.generate_answer(retriever=contextual_comp_retriever, user_query=q) for q in questions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Yow yow, nice to see you here, curious mind! Monosaccharides are a type of carbohydrate that cannot be hydrolyzed further to give simpler units of polyhydroxy aldehyde or ketone. Some common examples of monosaccharides include glucose, fructose, and ribose.',\n",
       " 'Yow yow, nice to see you here, curious mind! Reducing sugars are sugars that have free functional groups, specifically aldehydic or ketonic groups, which allow them to act as reducing agents. Examples of reducing sugars include maltose and lactose.',\n",
       " 'Yow yow, nice to see you here, curious mind! The two main functions of carbohydrates in plants are providing energy and serving as a structural component. They are used as storage molecules in the form of starch and they constitute the cell wall of plant cells in the form of cellulose.',\n",
       " 'Yow yow, nice to see you here, curious mind! \\nThe monosaccharides in your list are Ribose, 2-deoxyribose, galactose, and fructose. The disaccharides are maltose and lactose.',\n",
       " 'Yow yow, nice to see you here, curious mind! The term glycosidic linkage refers to the bond formed by the loss of a water molecule between two monosaccharide units through an oxygen atom. This linkage is commonly found in disaccharides and polysaccharides, playing a crucial role in the structure of carbohydrates.']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cands"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Individual BERT Scores for RAG w/ Contextual Compression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-large and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "calculating scores...\n",
      "computing bert embedding.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d74adda974e74daf841775942361b6ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing greedy matching.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98247b7d55ad442c95b4c524f93c743b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 1.43 seconds, 3.49 sentences/sec\n",
      "RAG w/ Contextual Compression | Precision: tensor([0.8856, 0.8496, 0.8555, 0.8914, 0.8434])\n",
      "RAG w/ Contextual Compression | Recall: tensor([0.9555, 0.8518, 0.9100, 0.9487, 0.8902])\n",
      "RAG w/ Contextual Compression | F1 Score: tensor([0.9192, 0.8507, 0.8820, 0.9191, 0.8662])\n"
     ]
    }
   ],
   "source": [
    "rag_P, rag_R, rag_F1 = score(cands, refs, lang=\"en\", verbose=True)\n",
    "\n",
    "print(\"RAG w/ Contextual Compression | Precision:\", rag_P)\n",
    "print(\"RAG w/ Contextual Compression | Recall:\", rag_R)\n",
    "print(\"RAG w/ Contextual Compression | F1 Score:\", rag_F1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate Overall BERT Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAG w/ Contextual Compression | Precision: 0.865\n",
      "RAG w/ Contextual Compression | Recall: 0.911\n",
      "RAG w/ Contextual Compression | F1 Score: 0.887\n"
     ]
    }
   ],
   "source": [
    "print(f\"RAG w/ Contextual Compression | Precision: {rag_P.mean():.3f}\")\n",
    "print(f\"RAG w/ Contextual Compression | Recall: {rag_R.mean():.3f}\")\n",
    "print(f\"RAG w/ Contextual Compression | F1 Score: {rag_F1.mean():.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation\n",
    "\n",
    "- **Precision** - 0.865 indicates that most of the content generated by model is relevant to the content of the human-generated references! --> **86% of the answers/candidates was generated by RAG correctly!** (generated right answers)\n",
    "- **Recall** - 0.91 indicates that the model has effectively captured info in the reference texts --> **91% of what should have been included in the generated text was actually included!** (only 9% of answers left behind)\n",
    "- **F1 Score** - harmonic mean of Precision & Recall\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
